---
layout: post
title: "Cilium 네트워킹 핸즈온 가이드 (6): Security & Tetragon"
date: 2025-09-01 10:00:00 +0900
categories: cilium security
tags: [cilium, security, tetragon, ebpf, network-policy, encryption, wireguard, tls-inspection, identity, kubernetes]
---

## Cilium 네트워킹 핸즈온 가이드 (6)

Cilium의 강력한 보안 기능과 Tetragon을 활용한 런타임 보안 모니터링을 실습을 통해 알아봅니다.  
이번 포스트에서는 Identity 기반 보안, 네트워크 정책, Wireguard 암호화, TLS 검사, 그리고 Tetragon을 통한 실시간 위협 탐지를 다룹니다.  
추가적으로 Cilium이 제공하는 L3-L7 제어를 담당하는 CRD를 알아보고 L3 제어를 핸즈온 합니다.

### 실습 환경 소개

K8S 1.33.4, Cilium 1.18.1 환경에서 보안 기능을 테스트합니다.

- Control Plane(k8s-ctr): 192.168.10.100
- Worker Node 1(k8s-w1): 192.168.10.101
- Worker Node 2(k8s-w2): 192.168.10.102

---

## Cilium Security 개요

### Identity 기반 보안

Cilium은 모든 엔드포인트에 고유한 Identity를 할당하여 보안을 구현합니다.

```bash
# Identity 확인
kubectl get ciliumendpoints.cilium.io -n kube-system

# NAME                              SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6
# coredns-674b8bbfcf-75xst          22940               ready            172.20.0.88    
# coredns-674b8bbfcf-9drgd          22940               ready            172.20.0.42    
# hubble-relay-fdd49b976-tgqnw      28238               ready            172.20.0.145   
# hubble-ui-655f947f96-qvpzs        736                 ready            172.20.0.220   
# metrics-server-5dd7b49d79-vcxc2   21387               ready            172.20.0.98   

kubectl get ciliumidentities.cilium.io

# NAME    NAMESPACE            AGE
# 11108   cilium-monitoring    12m
# 21387   kube-system          12m
# 22940   kube-system          12m
# 28238   kube-system          12m
# 4035    cilium-monitoring    12m
# 5257    local-path-storage   12m
# 736     kube-system          12m

# 특정 Identity 상세 정보
kubectl exec -it -n kube-system ds/cilium -- cilium identity list

# ...
# 736     k8s:app.kubernetes.io/name=hubble-ui
#         k8s:app.kubernetes.io/part-of=cilium
#         k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system
#         k8s:io.cilium.k8s.policy.cluster=default
#         k8s:io.cilium.k8s.policy.serviceaccount=hubble-ui
#         k8s:io.kubernetes.pod.namespace=kube-system
#         k8s:k8s-app=hubble-ui
# ...
```

Identity는 다음과 같은 특성을 가집니다.
- Labels 기반으로 자동 생성
- 클러스터 전체에서 유일한 ID
- 동일한 Security Labels를 가진 엔드포인트는 동일한 ID 공유

### Special Identities

Cilium은 특수한 목적의 예약된 Identity들을 제공합니다.

```bash
kubectl exec -it -n kube-system ds/cilium -- cilium identity list

# 1       reserved:host
#         reserved:kube-apiserver
# 2       reserved:world
# 3       reserved:unmanaged
# 4       reserved:health
# 5       reserved:init
# 6       reserved:remote-node
# 7       reserved:kube-apiserver
#         reserved:remote-node
# 8       reserved:ingress
```

| Identity                | ID  | 설명 |
|-------------------------|-----|------|
| reserved:unknown        | 0   | Identity를 파생할 수 없을 때 할당되는 값입니다. |
| reserved:host           | 1   | 로컬 호스트. 로컬 호스트 IP에서 발생하거나 로컬 호스트로 지정된 트래픽에 사용됩니다. |
| reserved:world          | 2   | 클러스터 외부의 모든 네트워크 엔드포인트. |
| reserved:unmanaged      | 3   | Cilium이 관리하지 않는 엔드포인트(예: Cilium 설치 전 생성된 Pod 등). |
| reserved:health         | 4   | Cilium 에이전트가 생성하는 헬스 체크 트래픽. |
| reserved:init           | 5   | Identity가 아직 할당되지 않은 엔드포인트(부트스트랩 단계 등, 메타데이터가 부족한 경우). Docker 플러그인 등에서 엔드포인트 생성 시 레이블을 알 수 없을 때 할당됩니다. |
| reserved:remote-node    | 6   | 모든 원격 클러스터 호스트의 집합. 로컬 노드가 아닌 다른 클러스터의 호스트 IP에서 발생하거나 해당 IP로 지정된 트래픽에 사용됩니다. |
| reserved:kube-apiserver | 7   | kube-apiserver를 백엔드로 사용하는 원격 노드(들). |
| reserved:ingress        | 8   | Ingress 프록시에서 발생하는 연결의 소스 IP에 할당됩니다. |

---

## 네트워크 정책 (Network Policy)

### 3가지 정책 형식

1. **NetworkPolicy**: 표준 K8S NetworkPolicy
2. **CiliumNetworkPolicy**: L3-L7 정책 지원
3. **CiliumClusterwideNetworkPolicy**: 클러스터 전체 정책

### Layer 3 정책

Layer 3 정책은 IP 주소나 엔드포인트 레이블을 기반으로 트래픽을 제어합니다. 다양한 방식으로 구현할 수 있습니다.  

#### 엔드포인트 기반 정책 (Endpoints-based)

두 엔드포인트가 Cilium에 의해 관리되고 레이블이 할당된 경우 사용합니다.

**샘플 애플리케이션 배포**

```bash
# Frontend Pod 배포
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: frontend
  labels:
    role: frontend
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    ports:
    - containerPort: 80
EOF

# Backend Pod 배포
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: backend
  labels:
    role: backend
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    ports:
    - containerPort: 80
EOF

# 테스트용 클라이언트 Pod 배포
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: client
  labels:
    role: client
spec:
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail", "-f", "/dev/null"]
EOF
```

**정책 적용 전 테스트**

```bash
# Backend Pod의 IP 확인
BACKEND_IP=$(kubectl get pod backend -o jsonpath='{.status.podIP}')
echo "Backend IP: $BACKEND_IP"

# Frontend에서 Backend로 접근 (성공)
kubectl exec frontend -- curl -s --connect-timeout 2 $BACKEND_IP

# Client에서 Backend로 접근 (성공)
kubectl exec client -- curl -s --connect-timeout 2 $BACKEND_IP

# <!DOCTYPE html>
# <html>
# <head>
# <title>Welcome to nginx!</title>
# <style>
# html { color-scheme: light dark; }
# body { width: 35em; margin: 0 auto;
# font-family: Tahoma, Verdana, Arial, sans-serif; }
# </style>
# </head>
# <body>
# <h1>Welcome to nginx!</h1>
# <p>If you see this page, the nginx web server is successfully installed and
# working. Further configuration is required.</p>

# <p>For online documentation and support please refer to
# <a href="http://nginx.org/">nginx.org</a>.<br/>
# Commercial support is available at
# <a href="http://nginx.com/">nginx.com</a>.</p>

# <p><em>Thank you for using nginx.</em></p>
# </body>
# </html>
```

**엔드포인트 기반 정책 적용**

```yaml
cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "l3-endpoints-rule"
spec:
  endpointSelector:
    matchLabels:
      role: backend
  ingress:
  - fromEndpoints:
    - matchLabels:
        role: frontend
EOF
```

**정책 적용 후 테스트**

```bash
# Frontend에서 Backend로 접근 (성공)
kubectl exec frontend -- curl -s --connect-timeout 2 $BACKEND_IP

# Client에서 Backend로 접근 (실패 - 타임아웃)
kubectl exec client -- curl -s --connect-timeout 2 $BACKEND_IP

# Hubble로 트래픽 확인
cilium hubble port-forward&
hubble observe --pod backend

# 접근제어, DROPPED
# Sep  6 15:12:46.890: default/client:55010 (ID:16200) <> default/backend:80 (ID:49668) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)
# Sep  6 15:12:46.890: default/client:55010 (ID:16200) <> default/backend:80 (ID:49668) Policy denied DROPPED (TCP Flags: SYN)
# Sep  6 15:12:47.943: default/client:55010 (ID:16200) <> default/backend:80 (ID:49668) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)
# Sep  6 15:12:47.943: default/client:55010 (ID:16200) <> default/backend:80 (ID:49668) Policy denied DROPPED (TCP Flags: SYN)

# 정책 삭제
kubectl delete CiliumNetworkPolicy l3-endpoints-rule
```

#### 서비스 기반 정책 (Services-based)

**Kubernetes 서비스를 활용한 정책 구성**

```bash
# Backend Service 생성
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  labels:
    app: backend
spec:
  selector:
    role: backend
  ports:
  - port: 80
    targetPort: 80
EOF

# 서비스 기반 정책
cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "l3-service-rule"
spec:
  endpointSelector:
    matchLabels:
      role: frontend
  egress:
  - toServices:
    - k8sService:
        serviceName: backend-service
        namespace: default
EOF

# Backend Svc의 IP 확인
BACKEND_IP=$(kubectl get svc backend-service -o jsonpath='{.spec.clusterIP}')
echo "Backend IP: $BACKEND_IP"

# Client Pod의 IP 확인
CLIENT_IP=$(kubectl get pod client -o jsonpath='{.status.podIP}')
echo "Client IP: $CLIENT_IP"

# Frontend에서 Backend로 접근 (성공)
kubectl exec frontend -- curl -s --connect-timeout 2 $BACKEND_IP

# Frontend에서 Client로 접근 (실패 - 타임아웃)
kubectl exec frontend -- curl -s --connect-timeout 2 $CLIENT_IP

# Hubble로 트래픽 확인
hubble observe --pod frontend

# EGRESS 송신 측 DENIED
# Sep  6 15:21:33.556: default/frontend:39402 (ID:4296) <> default/client:80 (ID:16200) policy-verdict:none EGRESS DENIED (TCP Flags: SYN)
# Sep  6 15:21:33.556: default/frontend:39402 (ID:4296) <> default/client:80 (ID:16200) Policy denied DROPPED (TCP Flags: SYN)
# Sep  6 15:21:34.611: default/frontend:39402 (ID:4296) <> default/client:80 (ID:16200) policy-verdict:none EGRESS DENIED (TCP Flags: SYN)
# Sep  6 15:21:34.611: default/frontend:39402 (ID:4296) <> default/client:80 (ID:16200) Policy denied DROPPED (TCP Flags: SYN)
```

#### 엔티티 기반 정책 (Entities-based)

**특별한 엔티티(host, world, kube-apiserver 등)에 대한 접근 제어**

```yaml
cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "l3-entity-rule"
spec:
  endpointSelector:
    matchLabels:
      role: frontend
  egress:
    # kube-apiserver 접근 허용
    - toEntities:
      - kube-apiserver
    # 클러스터 외부 접근 허용
    - toEntities:
      - world
EOF
```

#### 노드 기반 정책 (Node-based)

`fromNodes`/`toNodes` 정책은 **노드의 호스트 네트워크**에서 오는 트래픽을 제어합니다.  
일반 Pod 트래픽이 아닌 노드 자체 또는 `hostNetwork: true`인 Pod의 트래픽만 매칭됩니다.

**중요**: `fromNodes`/`toNodes` 사용 시 `enable-node-selector-labels` 플래그를 활성화해야 합니다.

```bash
# Cilium 노드 기반 정책을 위한 플래그 활성화
helm upgrade cilium cilium/cilium --version 1.18.1 --namespace kube-system --reuse-values \
  --set nodeSelectorLabels=true

kubectl rollout restart deploy cilium-operator -n kube-system
kubectl rollout restart ds cilium -n kube-system

# 설정 확인
cilium config view | grep enable-node-selector-labels

# enable-node-selector-labels                       true

# 각 노드에 테스트용 레이블 추가
kubectl label node k8s-w1 test-node=worker1
kubectl label node k8s-w2 test-node=worker2

# Control Plane 노드에 Pod 배포   k
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: control-client
  labels:
    role: control-client
spec:
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  tolerations:
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail", "-f", "/dev/null"]
EOF

# Worker1 노드에 Client 배포
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: worker-client
  labels:
    role: worker-client
spec:
  nodeSelector:
    test-node: worker1
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail", "-f", "/dev/null"]
EOF

# Worker2 노드에 Backend 배포
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: backend
  labels:
    role: backend
spec:
  nodeSelector:
    test-node: worker2
  containers:
  - name: nginx
    image: nginx:alpine
    ports:
    - containerPort: 80
EOF
```

**정책 적용 전 테스트**

```bash
# Pod 배포 확인
kubectl get pods -o wide

# NAME             READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES
# backend          1/1     Running   0          6s    172.20.2.57    k8s-w2    <none>           <none>
# control-client   1/1     Running   0          7s    172.20.0.142   k8s-ctr   <none>           <none>
# worker-client    1/1     Running   0          7s    172.20.1.90    k8s-w1    <none>           <none>

# Backend IP 확인
BACKEND_IP=$(kubectl get pod backend -o jsonpath='{.status.podIP}')
echo "Backend IP: $BACKEND_IP"

# Control Plane 노드에서 Backend 접근 (성공)
kubectl exec control-client -- curl -s --connect-timeout 2 $BACKEND_IP | head -5

# Worker 노드에서 Backend 접근 (성공)
kubectl exec worker-client -- curl -s --connect-timeout 2 $BACKEND_IP | head -5

# <!DOCTYPE html>
# <html>
# <head>
# <title>Welcome to nginx!</title>
# <style>
```

**노드 기반 정책 적용**

```bash
# Control Plane 노드에서만 접근 허용하는 정책
cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "l3-node-rule"
spec:
  endpointSelector:
    matchLabels:
      role: backend
  ingress:
    - fromNodes:
        - matchLabels:
            node-role.kubernetes.io/control-plane: ""
EOF
```

**정책 적용 후 테스트**

```bash
# 일반 Pod에서는 모두 차단됨 (fromNodes는 Pod 트래픽과 매칭되지 않음)
kubectl exec control-client -- curl -s --connect-timeout 2 $BACKEND_IP  # 실패
kubectl exec worker-client -- curl -s --connect-timeout 2 $BACKEND_IP   # 실패

# Hubble로 트래픽 모니터링
hubble observe --pod backend

# Sep  6 16:20:47.070: default/control-client:51012 (ID:53530) <> default/backend:80 (ID:49668) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)
# Sep  6 16:20:47.070: default/control-client:51012 (ID:53530) <> default/backend:80 (ID:49668) Policy denied DROPPED (TCP Flags: SYN)
# Sep  6 16:20:48.129: default/control-client:51012 (ID:53530) <> default/backend:80 (ID:49668) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)
# Sep  6 16:20:48.129: default/control-client:51012 (ID:53530) <> default/backend:80 (ID:49668) Policy denied DROPPED (TCP Flags: SYN)
# Sep  6 16:20:49.267: default/worker-client:45220 (ID:17873) <> default/backend:80 (ID:49668) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)
# Sep  6 16:20:49.267: default/worker-client:45220 (ID:17873) <> default/backend:80 (ID:49668) Policy denied DROPPED (TCP Flags: SYN)
# Sep  6 16:20:50.311: default/worker-client:45220 (ID:17873) <> default/backend:80 (ID:49668) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)
# Sep  6 16:20:50.311: default/worker-client:45220 (ID:17873) <> default/backend:80 (ID:49668) Policy denied DROPPED (TCP Flags: SYN)

# Host Network Pod 생성 (Control Plane)
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: host-control
spec:
  hostNetwork: true  # 중요!
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  tolerations:
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail", "-f", "/dev/null"]
EOF

# Host Network Pod에서 테스트 (성공!)
kubectl exec host-control -- curl -s --connect-timeout 2 $BACKEND_IP | head -5

# Sep  6 16:21:20.309: 192.168.10.100:53232 (ID:33554433) -> default/backend:80 (ID:49668) policy-verdict:L3-Only INGRESS ALLOWED (TCP Flags: SYN)
# Sep  6 16:21:20.309: 192.168.10.100:53232 (ID:33554433) -> default/backend:80 (ID:49668) to-endpoint FORWARDED (TCP Flags: SYN)
# Sep  6 16:21:20.309: 192.168.10.100:53232 (ID:33554433) <- default/backend:80 (ID:49668) to-network FORWARDED (TCP Flags: SYN, ACK)
# Sep  6 16:21:20.310: 192.168.10.100:53232 (ID:33554433) -> default/backend:80 (ID:49668) to-endpoint FORWARDED (TCP Flags: ACK)
# Sep  6 16:21:20.311: 192.168.10.100:53232 (ID:33554433) <> default/backend (ID:49668) pre-xlate-rev TRACED (TCP)
# Sep  6 16:21:20.315: 192.168.10.100:53232 (ID:33554433) -> default/backend:80 (ID:49668) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
# Sep  6 16:21:20.317: 192.168.10.100:53232 (ID:33554433) <> default/backend (ID:49668) pre-xlate-rev TRACED (TCP)
# Sep  6 16:21:20.317: 192.168.10.100:53232 (ID:33554433) <> default/backend (ID:49668) pre-xlate-rev TRACED (TCP)
# Sep  6 16:21:20.317: 192.168.10.100:53232 (ID:33554433) <- default/backend:80 (ID:49668) to-network FORWARDED (TCP Flags: ACK, PSH)
# Sep  6 16:21:20.319: 192.168.10.100:53232 (host) -> default/backend:80 (ID:49668) to-network FORWARDED (TCP Flags: SYN)
# Sep  6 16:21:20.320: 192.168.10.100:53232 (ID:33554433) -> default/backend:80 (ID:49668) to-endpoint FORWARDED (TCP Flags: ACK, FIN)
# Sep  6 16:21:20.321: 192.168.10.100:53232 (host) -> default/backend:80 (ID:49668) to-network FORWARDED (TCP Flags: ACK)
# Sep  6 16:21:20.322: 192.168.10.100:53232 (ID:33554433) <- default/backend:80 (ID:49668) to-network FORWARDED (TCP Flags: ACK, FIN)
# Sep  6 16:21:20.324: 192.168.10.100:53232 (host) -> default/backend:80 (ID:49668) to-network FORWARDED (TCP Flags: ACK, PSH)
# Sep  6 16:21:20.324: 192.168.10.100:53232 (ID:33554433) -> default/backend:80 (ID:49668) to-endpoint FORWARDED (TCP Flags: ACK)
# Sep  6 16:21:20.331: 192.168.10.100:53232 (host) -> default/backend:80 (ID:49668) to-network FORWARDED (TCP Flags: ACK, FIN)

# Worker 노드의 Host Network Pod 생성
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: host-worker
spec:
  hostNetwork: true
  nodeSelector:
    test-node: worker1
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail", "-f", "/dev/null"]
EOF

# Worker의 Host Network Pod에서 테스트 (실패!)
kubectl exec host-worker -- curl -s --connect-timeout 2 $BACKEND_IP

# Sep  6 16:21:54.491: 192.168.10.101:37488 (ID:33554434) <> default/backend:80 (ID:49668) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)
# Sep  6 16:21:54.491: 192.168.10.101:37488 (ID:33554434) <> default/backend:80 (ID:49668) Policy denied DROPPED (TCP Flags: SYN)
# Sep  6 16:21:54.491: 192.168.10.101:37488 (host) -> default/backend:80 (ID:49668) to-network FORWARDED (TCP Flags: SYN)
# Sep  6 16:21:55.526: 192.168.10.101:37488 (ID:33554434) <> default/backend:80 (ID:49668) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)
# Sep  6 16:21:55.526: 192.168.10.101:37488 (ID:33554434) <> default/backend:80 (ID:49668) Policy denied DROPPED (TCP Flags: SYN)
```

#### CIDR 기반 정책 (IP/CIDR-based)

**특정 IP 대역 제어**

```yaml
cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "l3-cidr-rule"
spec:
  endpointSelector:
    matchLabels:
      role: frontend
  egress:
  # 특정 IP만 허용
  - toCIDR:
    - 20.1.1.1/32
  # 특정 대역 허용, 일부 제외
  - toCIDRSet:
    - cidr: 10.0.0.0/8
      except:
      - 10.96.0.0/12
EOF
```

#### DNS 기반 정책 (DNS-based)

**도메인 이름 기반 트래픽 제어**

```yaml
cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "l3-dns-rule"
spec:
  endpointSelector:
    matchLabels:
      role: frontend
  egress:
  # DNS 쿼리 허용
  - toEndpoints:
    - matchLabels:
        "k8s:io.kubernetes.pod.namespace": kube-system
        "k8s:k8s-app": kube-dns
    toPorts:
    - ports:
      - port: "53"
        protocol: ANY
      rules:
        dns:
        - matchPattern: "*"
  # 특정 도메인 접근 허용
  - toFQDNs:
    - matchName: "example.com"
    - matchPattern: "*.example.com"
EOF
```

---

## DNS 기반 보안 정책

### 애플리케이션 배포

```bash
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: mediabot
  labels:
    org: empire
    class: mediabot
    app: mediabot
spec:
  containers:
  - name: mediabot
    image: quay.io/cilium/json-mock:v1.3.8@sha256:5aad04835eda9025fe4561ad31be77fd55309af8158ca8663a72f6abb78c2603
EOF

kubectl wait pod/mediabot --for=condition=Ready
```

### DNS Egress 정책 적용

**특정 도메인만 허용하는 정책**

```bash
# 정책 적용
cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "fqdn"
spec:
  endpointSelector:
    matchLabels:
      org: empire
      class: mediabot
  egress:
  - toFQDNs:
    - matchName: "api.github.com"
  - toEndpoints:
    - matchLabels:
        "k8s:io.kubernetes.pod.namespace": kube-system
        "k8s:k8s-app": kube-dns
    toPorts:
    - ports:
      - port: "53"
        protocol: ANY
      rules:
        dns:
        - matchPattern: "*"
EOF

# 테스트
kubectl exec mediabot -- curl -I -s https://api.github.com | head -1  # 성공

# Sep  6 16:30:32.324: default/mediabot (ID:27702) <> kube-system/coredns-674b8bbfcf-75xst:53 (ID:22940) post-xlate-fwd TRANSLATED (UDP)
# Sep  6 16:30:32.325: default/mediabot:52632 (ID:27702) -> kube-system/coredns-674b8bbfcf-75xst:53 (ID:22940) policy-verdict:L3-L4 EGRESS ALLOWED (UDP)

kubectl exec mediabot -- curl -I -s --max-time 5 https://support.github.com | head -1  # 실패

# Sep  6 16:31:07.007: default/mediabot:58898 (ID:27702) <> support.github.com:443 (world) policy-verdict:none EGRESS DENIED (TCP Flags: SYN)

hubble observe --pod mediabot

```

---

## WireGuard 암호화

### WireGuard 설정

```bash
# 커널 모듈 확인
grep -E 'CONFIG_WIREGUARD=m' /boot/config-$(uname -r)

# WireGuard 활성화
helm upgrade cilium cilium/cilium --version 1.18.1 --namespace kube-system --reuse-values \
  --set encryption.enabled=true --set encryption.type=wireguard

kubectl rollout restart deploy cilium-operator -n kube-system
kubectl rollout restart ds cilium -n kube-system

# 상태 확인
kubectl exec -it -n kube-system ds/cilium -- cilium encrypt status

# Encryption: Wireguard                 
# Interface: cilium_wg0
# 	Public key: ASDBXvsj1FO8/i616o9jnaLtlxr40pp3CGw7WPNO+zg=
# 	Number of peers: 2
```

### 암호화 확인

```bash
# WireGuard 인터페이스 확인
wg show

# interface: cilium_wg0
#   public key: vKot76km/vkpVAaI62tSgdQKQnIpW3jjh98FjMBwIig=
#   private key: (hidden)
#   listening port: 51871
#   fwmark: 0xe00

# peer: ASDBXvsj1FO8/i616o9jnaLtlxr40pp3CGw7WPNO+zg=
#   endpoint: 192.168.10.102:51871
#   allowed ips: 192.168.10.102/32, 172.20.2.174/32, 172.20.2.161/32, 172.20.2.0/24

# peer: cZlq7o9YqdgqRQEthadT3RQppEtVsN8sEn1uEf0jsV4=
#   endpoint: 192.168.10.101:51871
#   allowed ips: 172.20.1.141/32, 172.20.1.0/24, 172.20.1.183/32, 192.168.10.101/32

ip -d -c addr show cilium_wg0


# 샘플 애플리케이션 배포
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
EOF


# k8s-ctr 노드에 curl-pod 파드 배포
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF

# 암호화된 트래픽 캡처
kubectl exec -it curl-pod -- curl webpod
tcpdump -eni any udp port 51871

# 01:42:43.610384 eth1  Out ifindex 3 08:00:27:41:69:da ethertype IPv4 (0x0800), length 144: 192.168.10.100.51871 > 192.168.10.102.51871: UDP, length 96
# 01:42:43.612326 eth1  In  ifindex 3 08:00:27:6f:81:26 ethertype IPv4 (0x0800), length 144: 192.168.10.102.51871 > 192.168.10.100.51871: UDP, length 96
# 01:42:43.614541 eth1  Out ifindex 3 08:00:27:41:69:da ethertype IPv4 (0x0800), length 144: 192.168.10.100.51871 > 192.168.10.102.51871: UDP, length 96
# 01:42:43.614812 eth1  Out ifindex 3 08:00:27:41:69:da ethertype IPv4 (0x0800), length 208: 192.168.10.100.51871 > 192.168.10.102.51871: UDP, length 160
# 01:42:43.618541 eth1  In  ifindex 3 08:00:27:6f:81:26 ethertype IPv4 (0x0800), length 144: 192.168.10.102.51871 > 192.168.10.100.51871: UDP, length 96
# 01:42:43.620165 eth1  In  ifindex 3 08:00:27:6f:81:26 ethertype IPv4 (0x0800), length 464: 192.168.10.102.51871 > 192.168.10.100.51871: UDP, length 416
# 01:42:43.620685 eth1  Out ifindex 3 08:00:27:41:69:da ethertype IPv4 (0x0800), length 144: 192.168.10.100.51871 > 192.168.10.102.51871: UDP, length 96
# 01:42:43.622373 eth1  Out ifindex 3 08:00:27:41:69:da ethertype IPv4 (0x0800), length 144: 192.168.10.100.51871 > 192.168.10.102.51871: UDP, length 96
# 01:42:43.625309 eth1  In  ifindex 3 08:00:27:6f:81:26 ethertype IPv4 (0x0800), length 144: 192.168.10.102.51871 > 192.168.10.100.51871: UDP, length 96
# 01:42:43.627373 eth1  Out ifindex 3 08:00:27:41:69:da ethertype IPv4 (0x0800), length 144: 192.168.10.100.51871 > 192.168.10.102.51871: UDP, length 96

tcpdump -eni any udp port 51871 -w /tmp/wg.pcap 

![Wireshark](/assets/cilium/images/wireshark.png)
```

---

## TLS Interception

### TLS 가로채기 설정

**내부 CA 생성**

```bash
# CA 개인 키 생성
openssl genrsa -des3 -out myCA.key 2048

# CA 인증서 생성
openssl req -x509 -new -nodes -key myCA.key -sha256 -days 1825 -out myCA.crt

# Country Name (2 letter code) [AU]:KR
# State or Province Name (full name) [Some-State]:Seoul
# Locality Name (eg, city) []:Seoul
# Organization Name (eg, company) [Internet Widgits Pty Ltd]:Chris
# Organizational Unit Name (eg, section) []:None
# Common Name (e.g. server FQDN or YOUR name) []:chris.net 
# Email Address []:
```

**대상 서비스 인증서 생성**

```bash
# 개인 키 생성
openssl genrsa -out internal-httpbin.key 2048

# CSR 생성 (Common Name: httpbin.org)
openssl req -new -key internal-httpbin.key -out internal-httpbin.csr

# 서명된 인증서 생성
openssl x509 -req -days 360 -in internal-httpbin.csr -CA myCA.crt -CAkey myCA.key \
  -CAcreateserial -out internal-httpbin.crt -sha256

# 인증서 확인
openssl x509 -in internal-httpbin.crt -noout -text

# Signature Algorithm: sha256WithRSAEncryption
# Issuer: C = KR, ST = Seoul, L = Seoul, O = Chris, OU = None, CN = chris.net
# Validity
#     Not Before: Sep  6 17:08:34 2025 GMT
#     Not After : Sep  1 17:08:34 2026 GMT
# Subject: C = KR, ST = Seoul, L = Seoul, O = Chris, OU = None, CN = httpbin.org

# K8S Secret 생성
kubectl create secret tls httpbin-tls-data -n kube-system \
  --cert=internal-httpbin.crt --key=internal-httpbin.key

# Ubuntu의 경우 먼저 추가 CA 인증서를 클라이언트 Pod 파일 시스템에 복사합니다.
kubectl cp myCA.crt default/mediabot:/usr/local/share/ca-certificates/myCA.crt
kubectl exec -it mediabot -- ls -l /usr/local/share/ca-certificates/

# /etc/ssl/certs/ca-certificates.crt에 있는 신뢰할 수 있는 인증 기관의 글로벌 세트에 이 인증서를 추가하는 Ubuntu 전용 유틸리티 실행
kubectl exec -it mediabot -- ls -l /etc/ssl/certs/ca-certificates.crt # 사이즈, 생성/수정 날짜 확인
kubectl exec mediabot -- update-ca-certificates

# Updating certificates in /etc/ssl/certs...
# rehash: warning: skipping ca-certificates.crt,it does not contain exactly one certificate or CRL
# 1 added, 0 removed; done.
# Running hooks in /etc/ca-certificates/update.d...
# done.

kubectl exec -it mediabot -- ls -l /etc/ssl/certs/ca-certificates.crt # 사이즈, 생성/수정 날짜 확인

# Cilium Config 에 들어갈 자체 서명 신뢰 인증서 제공
kubectl cp default/mediabot:/etc/ssl/certs/ca-certificates.crt ca-certificates.crt

#  이 인증서 번들을 사용하여 Kubernetes 비밀을 생성하여 Cilium이 인증서 번들을 읽고 이를 사용하여 나가는 TLS 연결을 검증할 수 있도록 합니다.
kubectl create secret generic tls-orig-data -n kube-system --from-file=ca.crt=./ca-certificates.crt
kubectl get secret -n kube-system
```

**TLS 인식 정책 적용**

```bash
# 정책 적용 전
kubectl exec -it mediabot -- curl -sL 'https://httpbin.org/headers' -v # 서버 인증서 확인

# * Server certificate:
# *  subject: CN=httpbin.org
# *  start date: Jul 20 00:00:00 2025 GMT
# *  expire date: Aug 17 23:59:59 2026 GMT
# *  subjectAltName: host "httpbin.org" matched cert's "httpbin.org"
# *  issuer: C=US; O=Amazon; CN=Amazon RSA 2048 M03

# 정책 적용
kubectl create -f https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes-tls-inspection/l7-visibility-tls.yaml
kubectl get cnp

# 정책 적용 후
kubectl exec -it mediabot -- curl -sL 'https://httpbin.org/headers' -v # 서버 인증서 확인

# * Server certificate:
# *  subject: C=KR; ST=Seoul; L=Seoul; O=Chris; OU=None; CN=httpbin.org
# *  start date: Sep  6 17:08:34 2025 GMT
# *  expire date: Sep  1 17:08:34 2026 GMT
# *  common name: httpbin.org (matched)
# *  issuer: C=KR; ST=Seoul; L=Seoul; O=Chris; OU=None; CN=chris.net
# *  SSL certificate verify ok.

```

---

## Tetragon: 실시간 보안 모니터링

### Tetragon 설치

```bash
helm repo add cilium https://helm.cilium.io
helm install tetragon cilium/tetragon -n kube-system
kubectl rollout status -n kube-system ds/tetragon -w

# daemon set "tetragon" successfully rolled out
```

### 실행 모니터링

```bash
# 데모 애플리케이션 배포
kubectl create -f https://raw.githubusercontent.com/cilium/cilium/v1.18.1/examples/minikube/http-sw-app.yaml

# 확인
kubectl get pods

# Tetragon Pod 확인
POD=$(kubectl -n kube-system get pods -l 'app.kubernetes.io/name=tetragon' -o name \
  --field-selector spec.nodeName=$(kubectl get pod xwing -o jsonpath='{.spec.nodeName}'))

# 터미널1 - 실행 이벤트 모니터링
kubectl exec -ti -n kube-system $POD -c tetragon -- tetra getevents -o compact --pods xwing
```

### 파일 접근 모니터링

**민감한 파일 접근을 감지하는 정책**

```bash
# 읽기 모니터링 적용
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v1alpha1
kind: TracingPolicy
metadata:
  name: "sensitive-file-monitoring"
spec:
  kprobes:
  - call: "security_file_permission"
    syscall: false
    return: true
    args:
    - index: 0
      type: "file"
    - index: 1
      type: "int"
    returnArg:
      index: 0
      type: "int"
    returnArgAction: "Post"
    selectors:
    - matchArgs:
      - index: 0
        operator: "Prefix"
        values:
        - "/etc/shadow"
        - "/etc/passwd"
        - "/root/.ssh"
        - "/etc/sudoers"
        - "/etc/ssh"
        - "/var/log"
      - index: 1
        operator: "Equal"
        values:
        - "4"  # MAY_READ
EOF

# 민감한 파일 읽기 접근
kubectl exec xwing -- cat /etc/hostname
kubectl exec xwing -- cat /etc/passwd

# 🚀 process default/xwing /usr/bin/cat /etc/hostname                       
# 💥 exit    default/xwing /usr/bin/cat /etc/hostname 0            
# 🚀 process default/xwing /usr/bin/cat /etc/passwd                         
# 📚 read    default/xwing /usr/bin/cat /etc/passwd                         
# 📚 read    default/xwing /usr/bin/cat /etc/passwd                         
# 📚 read    default/xwing /usr/bin/cat /etc/passwd                         
# 📚 read    default/xwing /usr/bin/cat /etc/passwd                         
# 💥 exit    default/xwing /usr/bin/cat /etc/passwd 0

# 쓰기 모니터링 적용
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v1alpha1
kind: TracingPolicy
metadata:
  name: "write-monitoring"
spec:
  kprobes:
  - call: "security_file_permission"
    syscall: false
    return: true
    args:
    - index: 0
      type: "file"
    - index: 1
      type: "int"
    selectors:
    - matchArgs:
      - index: 0
        operator: "Prefix"
        values:
        - "/etc"
        - "/boot"
        - "/usr/bin"
        - "/usr/sbin"
      - index: 1
        operator: "Equal"
        values:
        - "2"  # MAY_WRITE
EOF

# /etc 디렉토리에 쓰기 시도
kubectl exec xwing -- sh -c 'echo "test" > /etc/test.txt'
kubectl exec xwing -- sh -c 'echo "test" >> /tmp/test.txt'

# 🚀 process default/xwing /usr/bin/sh -c "echo "test" > /etc/test.txt"     
# 💥 exit    default/xwing /usr/bin/sh -c "echo "test" > /etc/test.txt" 0 
# 🚀 process default/xwing /usr/bin/sh -c "echo "test" >> /tmp/test.txt"    
# 💥 exit    default/xwing /usr/bin/sh -c "echo "test" >> /tmp/test.txt" 0 
```

---
