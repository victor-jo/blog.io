---
layout: post
title: "Cilium ë„¤íŠ¸ì›Œí‚¹ í•¸ì¦ˆì˜¨ ê°€ì´ë“œ (3): BGP Control Planeê³¼ ClusterMesh"
date: 2025-08-16 10:00:00 +0900
categories: cilium kubernetes
tags: [cilium, bgp, clustermesh, kubernetes, ebpf, networking, kind, frr, ecmp]
---

## Cilium ë„¤íŠ¸ì›Œí‚¹ í•¸ì¦ˆì˜¨ ê°€ì´ë“œ (3)

ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œ Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ ìš´ì˜í•˜ë‹¤ ë³´ë©´ BGPë¥¼ í†µí•œ ë„¤íŠ¸ì›Œí¬ í†µí•©ê³¼ ë©€í‹° í´ëŸ¬ìŠ¤í„° ê°„ ì—°ê²°ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” Ciliumì˜ BGP Control Planeê³¼ ClusterMeshë¥¼ í™œìš©í•œ ê³ ê¸‰ ë„¤íŠ¸ì›Œí‚¹ ê¸°ëŠ¥ì„ ì‹¤ìŠµì„ í†µí•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

### ì‹¤ìŠµ í™˜ê²½ ì†Œê°œ

ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” BGP Control Plane í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ì¥ë¹„ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í™˜ê²½ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

- Control Plane(k8s-ctr): 192.168.10.100
- Worker Node 1(k8s-w1): 192.168.10.101
- Worker Node 2(k8s-w0): 192.168.20.100 (ë‹¤ë¥¸ ì„œë¸Œë„·)
- Router(FRR): 192.168.10.200, 192.168.20.200

### ê¸°ë³¸ í™˜ê²½ í™•ì¸
```bash
# k8s-ctr ë…¸ë“œ ì ‘ì†
vagrant ssh k8s-ctr

# í´ëŸ¬ìŠ¤í„° ì •ë³´ í™•ì¸
kubectl cluster-info
kubectl get node -owide

# Cilium ì„¤ì¹˜ ìƒíƒœ í™•ì¸
cilium status
cilium config view | grep -i bgp

# BGP Control Plane í™œì„±í™” í™•ì¸
# bgp-router-id-allocation-ip-pool                  
# bgp-router-id-allocation-mode                     default
# bgp-secrets-namespace                             kube-system
# enable-bgp-control-plane                          true
# enable-bgp-control-plane-status-report            true
```

---

## Cilium BGP Control Plane

### BGP Control Plane ì†Œê°œ

Cilium BGP Control Plane (BGPv2)ì€ Cilium Custom Resourcesë¥¼ í†µí•´ BGP ì„¤ì •ì„ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ê¸°ì¡´ ë„¤íŠ¸ì›Œí¬ ì¸í”„ë¼ì™€ì˜ í†µí•©ì„ ìœ„í•´ í‘œì¤€ BGP í”„ë¡œí† ì½œì„ ì§€ì›í•©ë‹ˆë‹¤.

### ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
```bash
# ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: webpod
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
EOF

# í…ŒìŠ¤íŠ¸ìš© curl íŒŒë“œ ë°°í¬
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail", "-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF

# ë°°í¬ í™•ì¸
kubectl get pod -owide
kubectl get svc webpod
```

### ì´ˆê¸° í†µì‹  ë¬¸ì œ í™•ì¸

```bash
# í†µì‹  í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ ë°œìƒ)
# ë‹¤ë¥¸ ì„œë¸Œë„·ê°„ í†µì‹  ë¶ˆê°€
kubectl exec -it curl-pod -- curl -s --connect-timeout 1 webpod

# ê°™ì€ ì„œë¸Œë„·ì˜ webpod ëŠ” í†µì‹ ë¨
# Hostname: webpod-65794679cc-7dbj2
# IP: 127.0.0.1
# IP: ::1
# IP: 172.20.0.11
# IP: fe80::c45:d1ff:fe3f:f4cf
# RemoteAddr: 172.20.0.4:38988
# GET / HTTP/1.1
# Host: webpod
# User-Agent: curl/8.14.1
# Accept: */*

# ë‹¤ë¥¸ ì„œë¸Œë„·ì˜ webpod ëŠ” í†µì‹ ì•ˆë¨
# command terminated with exit code 28
```

### Router FRR ì„¤ì •

#### FRR BGP êµ¬ì„±

FRR(Free Range Routing)ì€ Linux í”Œë«í¼ì—ì„œ ì‹¤í–‰ë˜ëŠ” ë¬´ë£Œ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ìš°íŒ… ì†Œí”„íŠ¸ì›¨ì–´ì…ë‹ˆë‹¤. FRRì€ BGP, OSPF, IS-IS, RIP, PIM, LDP ë“± ë‹¤ì–‘í•œ ë¼ìš°íŒ… í”„ë¡œí† ì½œì„ ì§€ì›í•©ë‹ˆë‹¤.

- **ë©€í‹° í”„ë¡œí† ì½œ ì§€ì›**: BGP, OSPF, IS-IS, RIP, PIM, LDP ë“± ì£¼ìš” ë¼ìš°íŒ… í”„ë¡œí† ì½œ ì§€ì›
- **ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜**: ê° í”„ë¡œí† ì½œì´ ë…ë¦½ì ì¸ ë°ëª¬ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ ì•ˆì •ì„± í–¥ìƒ
- **í‘œì¤€ ì¤€ìˆ˜**: RFC í‘œì¤€ì„ ì¤€ìˆ˜í•˜ì—¬ ë‹¤ë¥¸ ë²¤ë” ì¥ë¹„ì™€ í˜¸í™˜ì„± ë³´ì¥
- **í™•ì¥ì„±**: ëŒ€ê·œëª¨ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì—ì„œë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ ì œê³µ

ë³¸ ì‹¤ìŠµì—ì„œëŠ” FRRì„ ì‚¬ìš©í•˜ì—¬ Routerì—ì„œ BGPë¥¼ êµ¬ì„±í•˜ê³ , Cilium ë…¸ë“œë“¤ê³¼ BGP í”¼ì–´ë§ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ Pod CIDR ì •ë³´ë¥¼ ë¼ìš°íŒ… í…Œì´ë¸”ì— ì „íŒŒí•˜ì—¬ í´ëŸ¬ìŠ¤í„° ê°„ í†µì‹ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

```bash
# Router ì ‘ì† (ìƒˆ í„°ë¯¸ë„)
vagrant ssh router

# FRR ìƒíƒœ í™•ì¸
ps -ef | grep frr
sudo vtysh -c 'show running'
sudo vtysh -c 'show ip bgp summary'

# BGPê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë‚˜ ì•„ì§ í”¼ì–´ëŠ” ì—†ëŠ” ìƒíƒœ
# Building configuration...
# Current configuration:
# !
# frr version 8.4.4
# frr defaults traditional
# hostname router
# log syslog informational
# no ipv6 forwarding
# service integrated-vtysh-config
# !
# router bgp 65000
#  bgp router-id 192.168.10.200
#  no bgp ebgp-requires-policy
#  bgp graceful-restart
#  bgp bestpath as-path multipath-relax
#  !
#  address-family ipv4 unicast
#   network 10.10.1.0/24
#   maximum-paths 4
#  exit-address-family
# exit
# !
# end
# % No BGP neighbors found in VRF default

# FRRì— Cilium ë…¸ë“œë¥¼ BGP ì´ì›ƒìœ¼ë¡œ ì¶”ê°€
sudo vtysh
conf
router bgp 65000
  neighbor CILIUM peer-group
  neighbor CILIUM remote-as external
  neighbor 192.168.10.100 peer-group CILIUM
  neighbor 192.168.10.101 peer-group CILIUM
  neighbor 192.168.20.100 peer-group CILIUM
end
write memory
exit

# FRR BGP í”¼ì–´ í™•ì¸
sudo vtysh -c 'show ip bgp summary'

# 3ê°œ í”¼ì–´ ë“±ë¡
# IPv4 Unicast Summary (VRF default):
# BGP router identifier 192.168.10.200, local AS number 65000 vrf-id 0
# BGP table version 1
# RIB entries 1, using 192 bytes of memory
# Peers 3, using 2172 KiB of memory
# Peer groups 1, using 64 bytes of memory

# Neighbor        V         AS   MsgRcvd   MsgSent   TblVer  InQ OutQ  Up/Down State/PfxRcd   PfxSnt Desc
# 192.168.10.100  4          0         0         0        0    0    0    never       Active        0 N/A
# 192.168.10.101  4          0         0         0        0    0    0    never       Active        0 N/A
# 192.168.20.100  4          0         0         0        0    0    0    never       Active        0 N/A

# Total number of neighbors 3

# FRR ì¬ì‹œì‘
sudo systemctl restart frr

# ëª¨ë‹ˆí„°ë§ (ë³„ë„ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰)
sudo journalctl -u frr -f


# Aug 16 19:03:03 router watchfrr[4620]: [YFT0P-5Q5YX] Forked background command [pid 4621]: /usr/lib/frr/watchfrr.sh restart all
# Aug 16 19:03:03 router zebra[4633]: [VTVCM-Y2NW3] Configuration Read in Took: 00:00:00
# Aug 16 19:03:03 router bgpd[4638]: [VTVCM-Y2NW3] Configuration Read in Took: 00:00:00
# Aug 16 19:03:03 router staticd[4645]: [VTVCM-Y2NW3] Configuration Read in Took: 00:00:00
# Aug 16 19:03:03 router watchfrr[4620]: [QDG3Y-BY5TN] zebra state -> up : connect succeeded
# Aug 16 19:03:03 router watchfrr[4620]: [QDG3Y-BY5TN] bgpd state -> up : connect succeeded
# Aug 16 19:03:03 router watchfrr[4620]: [QDG3Y-BY5TN] staticd state -> up : connect succeeded
# Aug 16 19:03:03 router watchfrr[4620]: [KWE5Q-QNGFC] all daemons up, doing startup-complete notify
# Aug 16 19:03:03 router frrinit.sh[4610]:  * Started watchfrr
# Aug 16 19:03:03 router systemd[1]: Started frr.service - FRRouting.
```

### Cilium BGP ì„¤ì •

#### ë…¸ë“œ ë¼ë²¨ë§ ë° BGP Advertisement êµ¬ì„±

BGPë¥¼ ì‚¬ìš©í•  ë…¸ë“œë¥¼ ë¼ë²¨ë§í•˜ê³  BGP ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```bash
# BGPë¥¼ ì‚¬ìš©í•  ë…¸ë“œ ë¼ë²¨ë§
kubectl label nodes k8s-ctr k8s-w0 k8s-w1 enable-bgp=true
kubectl get node -l enable-bgp=true

# BGP ì„¤ì • ì ìš©
cat <<EOF | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumBGPAdvertisement
metadata:
  name: bgp-advertisements
  labels:
    advertise: bgp
spec:
  advertisements:
    - advertisementType: "PodCIDR"
---
apiVersion: cilium.io/v2
kind: CiliumBGPPeerConfig
metadata:
  name: cilium-peer
spec:
  timers:
    holdTimeSeconds: 9
    keepAliveTimeSeconds: 3
  ebgpMultihop: 2
  gracefulRestart:
    enabled: true
    restartTimeSeconds: 15
  families:
    - afi: ipv4
      safi: unicast
      advertisements:
        matchLabels:
          advertise: "bgp"
---
apiVersion: cilium.io/v2
kind: CiliumBGPClusterConfig
metadata:
  name: cilium-bgp
spec:
  nodeSelector:
    matchLabels:
      "enable-bgp": "true"
  bgpInstances:
  - name: "instance-65001"
    localASN: 65001
    peers:
    - name: "tor-switch"
      peerASN: 65000
      peerAddress: 192.168.10.200
      peerConfigRef:
        name: "cilium-peer"
EOF

# router ë…¸ë“œì˜ ë¡œê·¸ì—ì„œ bgp_update ì‹œê·¸ë„ í™•ì¸ ê°€ëŠ¥
# sudo journalctl -u frr -f
# Aug 16 19:09:26 router bgpd[4638]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.20.100 in vrf default
# Aug 16 19:09:26 router bgpd[4638]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.10.101 in vrf default
# Aug 16 19:09:26 router bgpd[4638]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.10.100 in vrf default

```

### BGP ì—°ê²° í™•ì¸

```bash
# BGP í”¼ì–´ ìƒíƒœ í™•ì¸
cilium bgp peers

# Node      Local AS   Peer AS   Peer Address     Session State   Uptime   Family         Received   Advertised
# k8s-ctr   65001      65000     192.168.10.200   established     38s      ipv4/unicast   4          2    
# k8s-w0    65001      65000     192.168.10.200   established     39s      ipv4/unicast   4          2    
# k8s-w1    65001      65000     192.168.10.200   established     39s      ipv4/unicast   4          2 

# BGP ë¼ìš°íŠ¸ í™•ì¸
cilium bgp routes available ipv4 unicast

# Node      VRouter   Prefix          NextHop   Age    Attrs
# k8s-ctr   65001     172.20.0.0/24   0.0.0.0   1m7s   [{Origin: i} {Nexthop: 0.0.0.0}]   
# k8s-w0    65001     172.20.2.0/24   0.0.0.0   1m7s   [{Origin: i} {Nexthop: 0.0.0.0}]   
# k8s-w1    65001     172.20.1.0/24   0.0.0.0   1m7s   [{Origin: i} {Nexthop: 0.0.0.0}]

# ì´ ê³¼ì •ì„ í†µí•´ Ciliumì´ BGPë¥¼ í†µí•´ ì™¸ë¶€ ë¼ìš°í„°ì™€ ì •ìƒì ìœ¼ë¡œ í†µì‹ í•˜ê³ , Kubernetes Pod ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­ì´ ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ë¡œ ê´‘ê³ ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# CiliumBGP ë¦¬ì†ŒìŠ¤ í™•ì¸
kubectl get ciliumbgpadvertisements,ciliumbgppeerconfigs,ciliumbgpclusterconfigs

# Routerì—ì„œ BGP ë¼ìš°íŒ… í…Œì´ë¸” í™•ì¸
vagrant ssh router
sudo vtysh -c 'show ip bgp summary'
sudo vtysh -c 'show ip bgp'
ip route | grep bgp

# 172.20.0.0/24 nhid 32 via 192.168.10.100 dev eth1 proto bgp metric 20 
# 172.20.1.0/24 nhid 28 via 192.168.10.101 dev eth1 proto bgp metric 20 
# 172.20.2.0/24 nhid 31 via 192.168.20.100 dev eth2 proto bgp metric 20
```

### í†µì‹  ë¬¸ì œ í•´ê²°

#### Pod ê°„ í†µì‹ ì„ ìœ„í•œ ë¼ìš°íŒ… ì„¤ì •

BGPë¡œ PodCIDR ì •ë³´ëŠ” êµí™˜ë˜ì§€ë§Œ, Ciliumì€ ê¸°ë³¸ì ìœ¼ë¡œ ì™¸ë¶€ ê²½ë¡œë¥¼ ì»¤ë„ ë¼ìš°íŒ… í…Œì´ë¸”ì— ì£¼ì…í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. <br/>
ë”°ë¼ì„œ ì´ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ ë¼ìš°íŒ… í…Œì´ë¸”ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
# k8s íŒŒë“œ ëŒ€ì—­(172.20.0.0/16)ì— ëŒ€í•œ ë¼ìš°íŒ… ì¶”ê°€
sudo ip route add 172.20.0.0/16 via 192.168.10.200
sshpass -p vagrant ssh vagrant@k8s-w1 "sudo ip route add 172.20.0.0/16 via 192.168.10.200"
sshpass -p vagrant ssh vagrant@k8s-w0 "sudo ip route add 172.20.0.0/16 via 192.168.20.200"

# ê° ë…¸ë“œì—ì„œ ë¼ìš°íŒ… í…Œì´ë¸”(ip route) í™•ì¸
ip route | grep 172.20
sshpass -p vagrant ssh vagrant@k8s-w1 "ip route | grep 172.20"
sshpass -p vagrant ssh vagrant@k8s-w0 "ip route | grep 172.20"

# í†µì‹  í…ŒìŠ¤íŠ¸ (ì„±ê³µ)
kubectl exec -it curl-pod -- curl -s webpod | grep Hostname

# Hubbleë¡œ í”Œë¡œìš° ëª¨ë‹ˆí„°ë§
cilium hubble port-forward&
hubble observe -f --protocol tcp --pod curl-pod

# Aug 16 15:00:53.736: default/curl-pod:38124 (ID:7810) <- default/webpod-65794679cc-7dbj2:80 (ID:3216) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
# Aug 16 15:00:53.737: default/curl-pod:38124 (ID:7810) -> default/webpod-65794679cc-7dbj2:80 (ID:3216) to-endpoint FORWARDED (TCP Flags: ACK, FIN)
# Aug 16 15:00:53.737: default/curl-pod:38124 (ID:7810) <- default/webpod-65794679cc-7dbj2:80 (ID:3216) to-endpoint FORWARDED (TCP Flags: ACK, FIN)
# Aug 16 15:00:53.737: default/curl-pod:38124 (ID:7810) -> default/webpod-65794679cc-7dbj2:80 (ID:3216) to-endpoint FORWARDED (TCP Flags: ACK)
```

---

## Service LoadBalancer IP BGP ê´‘ê³ 

### LoadBalancer IP Pool ìƒì„±

BGPë¥¼ í†µí•´ Service LoadBalancer IPë¥¼ ì™¸ë¶€ì— ê´‘ê³ í•˜ê¸° ìœ„í•´ ë¨¼ì € IP Poolì„ ìƒì„±í•©ë‹ˆë‹¤.

```bash
# IP Pool ì •ì˜
cat << EOF | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumLoadBalancerIPPool
metadata:
  name: "cilium-pool"
spec:
  allowFirstLastIPs: "No"
  blocks:
  - cidr: "172.16.1.0/24"
EOF

# Pool ìƒíƒœ í™•ì¸
kubectl get ippool

# Serviceë¥¼ LoadBalancerë¡œ ë³€ê²½
kubectl patch svc webpod -p '{"spec": {"type": "LoadBalancer"}}'

# External IP í™•ì¸
kubectl get svc webpod
LBIP=$(kubectl get svc webpod -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
echo "LoadBalancer IP: $LBIP"
```

### LoadBalancer IP BGP ê´‘ê³  ì„¤ì •

LoadBalancer IPë¥¼ BGP í”„ë¡œí† ì½œë¡œ ê´‘ê³ í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.

```bash
cat << EOF | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumBGPAdvertisement
metadata:
  name: bgp-advertisements-lb-exip-webpod
  labels:
    advertise: bgp
spec:
  advertisements:
    - advertisementType: "Service"
      service:
        addresses:
          - LoadBalancerIP
      selector:             
        matchExpressions:
          - { key: app, operator: In, values: [ webpod ] }
EOF

# BGP ë¼ìš°íŠ¸ ì •ì±… í™•ì¸
kubectl exec -it -n kube-system ds/cilium -- cilium-dbg bgp route-policies

# VRouter   Policy Name                                             Type     Match Peers         Match Families   Match Prefixes (Min..Max Len)   RIB Action   Path Actions
# 65001     allow-local                                             import                                                                        accept       
# 65001     tor-switch-ipv4-PodCIDR                                 export   192.168.10.200/32                    172.20.1.0/24 (24..24)          accept       
# 65001     tor-switch-ipv4-Service-webpod-default-LoadBalancerIP   export   192.168.10.200/32                    172.16.1.1/32 (32..32)          accept 

# Routerì—ì„œ BGP ë¼ìš°íŠ¸ í™•ì¸
sshpass -p 'vagrant' ssh vagrant@router ip -c route | grep bgp

# VIP ìƒì„± í™•ì¸
# 172.16.1.1 nhid 40 proto bgp metric 20 
# 172.20.0.0/24 nhid 32 via 192.168.10.100 dev eth1 proto bgp metric 20 
# 172.20.1.0/24 nhid 28 via 192.168.10.101 dev eth1 proto bgp metric 20 
# 172.20.2.0/24 nhid 31 via 192.168.20.100 dev eth2 proto bgp metric 20 

sshpass -p 'vagrant' ssh vagrant@router "sudo vtysh -c 'show ip bgp 172.16.1.1/32'"

# VIP ì— ëŒ€í•œ BGP Routing Table ìƒì„± í™•ì¸
# BGP routing table entry for 172.16.1.1/32, version 11
# Paths: (3 available, best #2, table default)
#   Advertised to non peer-group peers:
#   192.168.10.100 192.168.10.101 192.168.20.100
#   65001
#     192.168.20.100 from 192.168.20.100 (192.168.20.100)
#       Origin IGP, valid, external, multipath
#       Last update: Sat Aug 16 19:29:12 2025
#   65001
#     192.168.10.100 from 192.168.10.100 (192.168.10.100)
#       Origin IGP, valid, external, multipath, best (Router ID)
#       Last update: Sat Aug 16 19:29:12 2025
#   65001
#     192.168.10.101 from 192.168.10.101 (192.168.10.101)
#       Origin IGP, valid, external, multipath
#       Last update: Sat Aug 16 19:29:12 2025

# Routerì—ì„œ LoadBalancer IPë¡œ ì ‘ê·¼ (ì •ìƒ í™•ì¸)
sshpass -p 'vagrant' ssh vagrant@router curl -s $LBIP | grep Hostname
```

### External Traffic Policy

#### Local ëª¨ë“œ ì„¤ì • (ì†ŒìŠ¤ IP ë³´ì¡´)

External Traffic Policyë¥¼ Localë¡œ ì„¤ì •í•˜ë©´ ì‹¤ì œ íŒŒë“œê°€ ìˆëŠ” ë…¸ë“œë§Œ BGPë¡œ ê´‘ê³ ë©ë‹ˆë‹¤.

```bash
# External Traffic Policyë¥¼ Localë¡œ ë³€ê²½
kubectl patch service webpod -p '{"spec":{"externalTrafficPolicy":"Local"}}'

# BGP ë¼ìš°íŠ¸ í™•ì¸ (íŒŒë“œê°€ ìˆëŠ” ë…¸ë“œë§Œ ê´‘ê³ )
sshpass -p 'vagrant' ssh vagrant@router "sudo vtysh -c 'show ip bgp'"
sshpass -p 'vagrant' ssh vagrant@router "sudo vtysh -c 'show ip bgp 172.16.1.1/32'"
sshpass -p 'vagrant' ssh vagrant@router "ip -c route"

# ì ‘ì† í…ŒìŠ¤íŠ¸
LBIP=172.16.1.1
for i in {1..100}; do
  curl -s $LBIP | grep Hostname
done | sort | uniq -c | sort -nr
```

#### ECMP Hash Policy ìµœì í™”

ECMP(Equal Cost Multi-Path)ë¡œ ë¡œë“œë°¸ëŸ°ì‹± íš¨ìœ¨ì„ ë†’ì´ê¸° ìœ„í•´ Hash Policyë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.

```bash
# Linux ECMP Hash Policyë¥¼ L4 ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½
sshpass -p 'vagrant' ssh vagrant@router << 'EOF'
sudo sysctl -w net.ipv4.fib_multipath_hash_policy=1
sudo echo "net.ipv4.fib_multipath_hash_policy=1" >> /etc/sysctl.conf
EOF

# ë¶€í•˜ë¶„ì‚° í…ŒìŠ¤íŠ¸
for i in {1..100}; do
  curl -s $LBIP | grep Hostname
done | sort | uniq -c | sort -nr
```

---

## ClusterMeshë¡œ ë©€í‹° í´ëŸ¬ìŠ¤í„° êµ¬ì„±

### Kind í´ëŸ¬ìŠ¤í„° ë°°í¬

ClusterMesh ì‹¤ìŠµì„ ìœ„í•´ Kind(Kubernetes in Docker)ë¡œ ë‘ ê°œì˜ í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

#### Kind ì„¤ì¹˜

Kind(Kubernetes in Docker)ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
brew install kind
```

#### West/East í´ëŸ¬ìŠ¤í„° ìƒì„±

```bash
# West í´ëŸ¬ìŠ¤í„° ìƒì„±
kind create cluster --name west --image kindest/node:v1.33.2 --config - <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
- role: worker
networking:
  podSubnet: "10.0.0.0/16"
  serviceSubnet: "10.2.0.0/16"
  disableDefaultCNI: true
  kubeProxyMode: none
EOF

# East í´ëŸ¬ìŠ¤í„° ìƒì„±
kind create cluster --name east --image kindest/node:v1.33.2 --config - <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 31000
    hostPort: 31000
  - containerPort: 31001
    hostPort: 31001
- role: worker
networking:
  podSubnet: "10.1.0.0/16"
  serviceSubnet: "10.3.0.0/16"
  disableDefaultCNI: true
  kubeProxyMode: none
EOF

# ì»¨í…ìŠ¤íŠ¸ í™•ì¸
kubectl config get-contexts

# alias ì„¤ì •
alias kwest='kubectl --context kind-west'
alias keast='kubectl --context kind-east'

# ë…¸ë“œ í™•ì¸
kwest get node -owide
keast get node -owide

# NAME                 STATUS     ROLES           AGE     VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION                         CONTAINER-RUNTIME
# west-control-plane   NotReady   control-plane   3m25s   v1.33.2   192.168.97.3   <none>        Debian GNU/Linux 12 (bookworm)   6.14.10-orbstack-00291-g1b252bd3edea   containerd://2.1.3
# west-worker          NotReady   <none>          3m12s   v1.33.2   192.168.97.2   <none>        Debian GNU/Linux 12 (bookworm)   6.14.10-orbstack-00291-g1b252bd3edea   containerd://2.1.3
# NAME                 STATUS     ROLES           AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION                         CONTAINER-RUNTIME
# east-control-plane   NotReady   control-plane   62s   v1.33.2   192.168.97.4   <none>        Debian GNU/Linux 12 (bookworm)   6.14.10-orbstack-00291-g1b252bd3edea   containerd://2.1.3
# east-worker          NotReady   <none>          48s   v1.33.2   192.168.97.5   <none>        Debian GNU/Linux 12 (bookworm)   6.14.10-orbstack-00291-g1b252bd3edea   containerd://2.1.3
```

### Cilium CNI ì„¤ì¹˜

ClusterMeshë¥¼ ìœ„í•œ Ciliumì„ ê° í´ëŸ¬ìŠ¤í„°ì— ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
# Cilium CNI ì„¤ì¹˜
CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
CLI_ARCH=amd64
if [ "$(uname -m)" = "arm64" ]; then CLI_ARCH=arm64; fi
curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-darwin-${CLI_ARCH}.tar.gz{,.sha256sum}
shasum -a 256 -c cilium-darwin-${CLI_ARCH}.tar.gz.sha256sum
sudo tar xzvfC cilium-darwin-${CLI_ARCH}.tar.gz /usr/local/bin
rm cilium-darwin-${CLI_ARCH}.tar.gz{,.sha256sum}


> **âš ï¸ ì£¼ì˜:** ì•„ë˜ ë‚´ìš©ì€ 1.18.0 í…ŒìŠ¤íŠ¸ì‹œ ê¸€ë¡œë²Œ ì„œë¹„ìŠ¤ í´ëŸ¬ìŠ¤í„° ë©”ì‹œ ë¶„ì‚°ì²˜ë¦¬ê°€ ì •ìƒì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ì‹  ë¶„ë“¤ì€ ì§„í–‰ í•˜ì‹  í›„ ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ì˜ Cilium ì„ ë‚ ë¦¬ê³  1.17.6 ë²„ì „ìœ¼ë¡œ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸ í•˜ì‹œê¸¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.

# Cilium ê¸°ì¡´ ë°°í¬ ì‚­ì œ
cilium uninstall --context kind-west
cilium uninstall --context kind-east

# West í´ëŸ¬ìŠ¤í„° Cilium ì„¤ì¹˜
cilium install --version 1.17.6 \
  --set ipam.mode=kubernetes \
  --set kubeProxyReplacement=true \
  --set bpf.masquerade=true \
  --set endpointHealthChecking.enabled=false \
  --set healthChecking=false \
  --set operator.replicas=1 \
  --set debug.enabled=true \
  --set routingMode=native \
  --set autoDirectNodeRoutes=true \
  --set ipv4NativeRoutingCIDR=10.0.0.0/16 \
  --set ipMasqAgent.enabled=true \
  --set ipMasqAgent.config.nonMasqueradeCIDRs='{10.1.0.0/16}' \
  --set cluster.name=west \
  --set cluster.id=1 \
  --context kind-west

# East í´ëŸ¬ìŠ¤í„° Cilium ì„¤ì¹˜
cilium install --version 1.17.6 \
  --set ipam.mode=kubernetes \
  --set kubeProxyReplacement=true \
  --set bpf.masquerade=true \
  --set endpointHealthChecking.enabled=false \
  --set healthChecking=false \
  --set operator.replicas=1 \
  --set debug.enabled=true \
  --set routingMode=native \
  --set autoDirectNodeRoutes=true \
  --set ipv4NativeRoutingCIDR=10.1.0.0/16 \
  --set ipMasqAgent.enabled=true \
  --set ipMasqAgent.config.nonMasqueradeCIDRs='{10.0.0.0/16}' \
  --set cluster.name=east \
  --set cluster.id=2 \
  --context kind-east

# ìƒíƒœ í™•ì¸
cilium status --context kind-west
cilium status --context kind-east
```

### ClusterMesh ì„¤ì •

#### í´ëŸ¬ìŠ¤í„° ì—°ê²°

ë‘ í´ëŸ¬ìŠ¤í„°ë¥¼ ClusterMeshë¡œ ì—°ê²°í•©ë‹ˆë‹¤.

```bash
# Shared Certificate Authority ì„¤ì •
keast delete secret -n kube-system cilium-ca
kubectl --context kind-west get secret -n kube-system cilium-ca -o yaml | \
kubectl --context kind-east create -f -

# ClusterMesh í™œì„±í™”
cilium clustermesh enable --service-type NodePort --enable-kvstoremesh=false --context kind-west
cilium clustermesh enable --service-type NodePort --enable-kvstoremesh=false --context kind-east

# í´ëŸ¬ìŠ¤í„° ì—°ê²°
cilium clustermesh connect --context kind-west --destination-context kind-east

# ìƒíƒœ í™•ì¸
cilium clustermesh status --context kind-west --wait
cilium clustermesh status --context kind-east --wait

# ë…¸ë“œ ëª©ë¡ í™•ì¸ (ì–‘ìª½ í´ëŸ¬ìŠ¤í„° ë…¸ë“œê°€ ëª¨ë‘ ë³´ì„)
kwest exec -it -n kube-system ds/cilium -c cilium-agent -- cilium node list
keast exec -it -n kube-system ds/cilium -c cilium-agent -- cilium node list

# Name                      IPv4 Address   Endpoint CIDR   IPv6 Address   Endpoint CIDR   Source
# east/east-control-plane   192.168.97.4   10.1.0.0/24                                    clustermesh
# east/east-worker          192.168.97.5   10.1.1.0/24                                    clustermesh
# west/west-control-plane   192.168.97.3   10.0.0.0/24                                    local
# west/west-worker          192.168.97.2   10.0.1.0/24                                    custom-resource
# Name                      IPv4 Address   Endpoint CIDR   IPv6 Address   Endpoint CIDR   Source
# east/east-control-plane   192.168.97.4   10.1.0.0/24                                    custom-resource
# east/east-worker          192.168.97.5   10.1.1.0/24                                    local
# west/west-control-plane   192.168.97.3   10.0.0.0/24                                    clustermesh
# west/west-worker          192.168.97.2   10.0.1.0/24                                    clustermesh
```

### Global Service ë°°í¬

ë©€í‹° í´ëŸ¬ìŠ¤í„° í™˜ê²½ì—ì„œ Global Serviceë¥¼ ë°°í¬í•˜ì—¬ í´ëŸ¬ìŠ¤í„° ê°„ ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

```bash
# ê° ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œì— ëŒ€í•˜ì—¬ Pod ë°°ì¹˜ë  ìˆ˜ ìˆë„ë¡ Taint ì„¤ì • í•´ì œ
keast taint nodes east-control-plane node-role.kubernetes.io/control-plane:NoSchedule-
kwest taint nodes west-control-plane node-role.kubernetes.io/control-plane:NoSchedule-

# West í´ëŸ¬ìŠ¤í„°ì— ì„œë¹„ìŠ¤ ë°°í¬
cat << EOF | kubectl apply --context kind-west -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - webpod
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  annotations:
    service.cilium.io/global: "true"
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
EOF

# East í´ëŸ¬ìŠ¤í„°ì—ë„ ë™ì¼ ì„œë¹„ìŠ¤ ë°°í¬
cat << EOF | kubectl apply --context kind-east -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - webpod
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  annotations:
    service.cilium.io/global: "true"
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
EOF

kwest get svc -l app=webpod
kwest get pods -l app=webpod -owide
keast get svc -l app=webpod
keast get pods -l app=webpod -owide

# NAME     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
# webpod   ClusterIP   10.2.175.143   <none>        80/TCP    56s
# NAME                      READY   STATUS    RESTARTS   AGE   IP           NODE                 NOMINATED NODE   READINESS GATES
# webpod-74f6f7bd86-5d54n   1/1     Running   0          56s   10.0.1.75    west-worker          <none>           <none>
# webpod-74f6f7bd86-tfrmk   1/1     Running   0          56s   10.0.0.103   west-control-plane   <none>           <none>

# NAME     TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
# webpod   ClusterIP   10.3.128.57   <none>        80/TCP    50s
# NAME                      READY   STATUS    RESTARTS   AGE   IP           NODE                 NOMINATED NODE   READINESS GATES
# webpod-74f6f7bd86-f5sq9   1/1     Running   0          50s   10.1.0.141   east-control-plane   <none>           <none>
# webpod-74f6f7bd86-zzg4b   1/1     Running   0          50s   10.1.1.36    east-worker          <none>           <none>

# ì„œë¹„ìŠ¤ ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
kwest exec -it -n kube-system ds/cilium -c cilium-agent -- cilium service list --clustermesh-affinity

# 14   10.2.175.143:80/TCP      ClusterIP      1 => 10.0.1.75:80/TCP (active)        
#                                              2 => 10.0.0.103:80/TCP (active)       
#                                              3 => 10.1.0.141:80/TCP (active)       
#                                              4 => 10.1.1.36:80/TCP (active) 

keast exec -it -n kube-system ds/cilium -c cilium-agent -- cilium service list --clustermesh-affinity

# 14   10.3.128.57:80/TCP       ClusterIP      1 => 10.0.0.103:80/TCP (active)       
#                                              2 => 10.0.1.75:80/TCP (active)        
#                                              3 => 10.1.0.141:80/TCP (active)       
#                                              4 => 10.1.1.36:80/TCP (active)

```

#### í…ŒìŠ¤íŠ¸ìš© Pod ë°°í¬

ê° í´ëŸ¬ìŠ¤í„°ì— í…ŒìŠ¤íŠ¸ìš© Podë¥¼ ë°°í¬í•˜ì—¬ í¬ë¡œìŠ¤ í´ëŸ¬ìŠ¤í„° í†µì‹ ì„ í™•ì¸í•©ë‹ˆë‹¤.

```bash
# West í´ëŸ¬ìŠ¤í„°ì— curl-pod ë°°í¬
cat << EOF | kubectl apply --context kind-west -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF

# East í´ëŸ¬ìŠ¤í„°ì— curl-pod ë°°í¬
cat << EOF | kubectl apply --context kind-east -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF

# í†µì‹  í…ŒìŠ¤íŠ¸ (ì–‘ìª½ í´ëŸ¬ìŠ¤í„°ì˜ Podì—ì„œ ì‘ë‹µ)
kubectl exec -it curl-pod --context kind-west -- sh -c \
  'while true; do curl -s --connect-timeout 1 webpod; sleep 1; echo "---"; done;'

kubectl exec -it curl-pod --context kind-east -- sh -c \
  'while true; do curl -s --connect-timeout 1 webpod; sleep 1; echo "---"; done;'

# Local affinity ì„¤ì •
kwest annotate service webpod service.cilium.io/affinity=local --overwrite
keast annotate service webpod service.cilium.io/affinity=local --overwrite

# ìƒíƒœ í™•ì¸
kwest exec -it -n kube-system ds/cilium -c cilium-agent -- cilium service list --clustermesh-affinity

# ìê¸° ìœ„ì¹˜ì˜ ë…¸ë“œì— ìˆëŠ” EndPoint preferred ë§ˆí‚¹ ì¶”ê°€
# 14   10.2.175.143:80/TCP      ClusterIP      1 => 10.0.1.75:80/TCP (active) (preferred)    
#                                              2 => 10.0.0.103:80/TCP (active) (preferred)   
#                                              3 => 10.1.0.141:80/TCP (active)               
#                                              4 => 10.1.1.36:80/TCP (active) 

keast exec -it -n kube-system ds/cilium -c cilium-agent -- cilium service list --clustermesh-affinity

# ìê¸° ìœ„ì¹˜ì˜ ë…¸ë“œì— ìˆëŠ” EndPoint preferred ë§ˆí‚¹ ì¶”ê°€
# 14   10.3.128.57:80/TCP       ClusterIP      1 => 10.0.0.103:80/TCP (active)               
#                                              2 => 10.0.1.75:80/TCP (active)                
#                                              3 => 10.1.0.141:80/TCP (active) (preferred)   
#                                              4 => 10.1.1.36:80/TCP (active) (preferred)

# í…ŒìŠ¤íŠ¸ (ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ì˜ Podì—ì„œë§Œ ì‘ë‹µ)
kubectl exec -it curl-pod --context kind-west -- sh -c \
  'while true; do curl -s --connect-timeout 1 webpod; sleep 1; echo "---"; done;'

# ìê¸° ìœ„ì¹˜ì˜ ë…¸ë“œì— EndPoint ê°€ ì—†ëŠ” ìƒíƒœ í…ŒìŠ¤íŠ¸
kwest scale deployment webpod --replicas 0

# í…ŒìŠ¤íŠ¸ (ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ì˜ Podì—ì„œë§Œ ì‘ë‹µ)
kubectl exec -it curl-pod --context kind-west -- sh -c \
  'while true; do curl -s --connect-timeout 1 webpod; sleep 1; echo "---"; done;'

# ì›ë³µ
kwest scale deployment webpod --replicas 2

# Remote affinity ì„¤ì •
kwest annotate service webpod service.cilium.io/affinity=remote --overwrite
keast annotate service webpod service.cilium.io/affinity=remote --overwrite

# í…ŒìŠ¤íŠ¸ (ì›ê²© í´ëŸ¬ìŠ¤í„°ì˜ Podì—ì„œ ì‘ë‹µ)
kubectl exec -it curl-pod --context kind-west -- sh -c \
  'while true; do curl -s --connect-timeout 1 webpod; sleep 1; echo "---"; done;'

# ë™ì‘ í™•ì¸ ëª¨ë‘ì™„ë£Œ, ì „ì²´ Kind í´ëŸ¬ìŠ¤í„° ì •ë¦¬
kind delete clusters east
kind delete clusters west
```

---

## Multi-Cluster Services (MCS) API

### MCS API ì†Œê°œ

Kubernetes Multi-Cluster Services APIëŠ” KEP-1645ì—ì„œ ì •ì˜ëœ í‘œì¤€ APIë¡œ, ì—¬ëŸ¬ í´ëŸ¬ìŠ¤í„°ì— ê±¸ì³ ì„œë¹„ìŠ¤ë¥¼ ë…¸ì¶œí•˜ê³  ì‚¬ìš©í•˜ëŠ” í‘œì¤€í™”ëœ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. Ciliumì€ v1.17ë¶€í„° MCS APIë¥¼ ì§€ì›í•˜ì—¬ ClusterMesh ê¸°ë°˜ì˜ ë©€í‹° í´ëŸ¬ìŠ¤í„° ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**MCS APIì˜ ì£¼ìš” ë¦¬ì†ŒìŠ¤:**
- **ServiceExport**: ì„œë¹„ìŠ¤ë¥¼ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ì— ë…¸ì¶œí•˜ê¸° ìœ„í•œ ë¦¬ì†ŒìŠ¤
- **ServiceImport**: ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ì—ì„œ ë…¸ì¶œëœ ì„œë¹„ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ë¦¬ì†ŒìŠ¤ (ìë™ ìƒì„±)

### MCS API ì„¤ì •

#### Kind í´ëŸ¬ìŠ¤í„° ì‹¤ìŠµí™˜ê²½ êµ¬ì„±

```bash
# West í´ëŸ¬ìŠ¤í„°
kind create cluster --name west --image kindest/node:v1.33.2 --config - <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
- role: worker
networking:
  podSubnet: "10.0.0.0/16"
  serviceSubnet: "10.2.0.0/16"
  disableDefaultCNI: true
  kubeProxyMode: none
EOF

# East í´ëŸ¬ìŠ¤í„°
kind create cluster --name east --image kindest/node:v1.33.2 --config - <<EOF
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
- role: worker
networking:
  podSubnet: "10.1.0.0/16"
  serviceSubnet: "10.3.0.0/16"
  disableDefaultCNI: true
  kubeProxyMode: none
EOF

# alias ì„¤ì •
alias kwest='kubectl --context kind-west'
alias keast='kubectl --context kind-east'
```

#### MCS API CRD ì„¤ì¹˜

```bash
# MCS API CRDs ì„¤ì¹˜ (West í´ëŸ¬ìŠ¤í„°)
kubectl apply --context kind-west -f https://raw.githubusercontent.com/kubernetes-sigs/mcs-api/master/config/crd/multicluster.x-k8s.io_serviceexports.yaml
kubectl apply --context kind-west -f https://raw.githubusercontent.com/kubernetes-sigs/mcs-api/master/config/crd/multicluster.x-k8s.io_serviceimports.yaml

# MCS API CRDs ì„¤ì¹˜ (East í´ëŸ¬ìŠ¤í„°)
kubectl apply --context kind-east -f https://raw.githubusercontent.com/kubernetes-sigs/mcs-api/master/config/crd/multicluster.x-k8s.io_serviceexports.yaml
kubectl apply --context kind-east -f https://raw.githubusercontent.com/kubernetes-sigs/mcs-api/master/config/crd/multicluster.x-k8s.io_serviceimports.yaml

# CRD í™•ì¸
kwest get crd | grep multicluster
keast get crd | grep multicluster
```

#### Cilium ì„¤ì¹˜ (MCS API ì§€ì› í¬í•¨)

```bash
# West í´ëŸ¬ìŠ¤í„° Cilium ì„¤ì¹˜
cilium install --version 1.18.1 \
  --set ipam.mode=kubernetes \
  --set kubeProxyReplacement=true \
  --set cluster.name=west \
  --set cluster.id=1 \
  --context kind-west

# East í´ëŸ¬ìŠ¤í„° Cilium ì„¤ì¹˜
cilium install --version 1.18.1 \
  --set ipam.mode=kubernetes \
  --set kubeProxyReplacement=true \
  --set cluster.name=east \
  --set cluster.id=2 \
  --context kind-east

# Helm repo ì¶”ê°€
helm repo add cilium https://helm.cilium.io/
helm repo update

# MCS API ì§€ì› í™œì„±í™”
kubectl config use-context kind-west
helm upgrade cilium cilium/cilium --version 1.18.1 \
  --namespace kube-system \
  --reuse-values \
  --set clustermesh.enableMCSAPISupport=true


kubectl config use-context kind-east
helm upgrade cilium cilium/cilium --version 1.18.1 \
  --namespace kube-system \
  --reuse-values \
  --set clustermesh.enableMCSAPISupport=true

# Cilium ì¬ì‹œì‘
kubectl rollout restart ds/cilium -n kube-system --context kind-west
kubectl rollout restart ds/cilium -n kube-system --context kind-east

# í™œì„±í™” ì—¬ë¶€ í™•ì¸
cilium config view --context kind-west | grep mcs
cilium config view --context kind-east | grep mcs
```

#### CoreDNS ë©€í‹°í´ëŸ¬ìŠ¤í„° í”ŒëŸ¬ê·¸ì¸ ì„¤ì •

MCS APIë¥¼ ì™„ì „íˆ í™œìš©í•˜ë ¤ë©´ CoreDNSì— multicluster í”ŒëŸ¬ê·¸ì¸ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ì´ í”ŒëŸ¬ê·¸ì¸ì€ `clusterset.local` ë„ë©”ì¸ì„ í†µí•´ ì„œë¹„ìŠ¤ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

> **âš ï¸ ì£¼ì˜:** ê¸°ë³¸ CoreDNSëŠ” multicluster í”ŒëŸ¬ê·¸ì¸ì„ í¬í•¨í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¬ì»´íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.

##### CoreDNS ì¬ì»´íŒŒì¼ (ì˜µì…˜)

```bash
# CoreDNS ì†ŒìŠ¤ í´ë¡ 
git clone https://github.com/coredns/coredns.git
cd coredns
git checkout v1.11.4

# plugins.cfg íŒŒì¼ì— multicluster í”ŒëŸ¬ê·¸ì¸ ì¶”ê°€
# kubernetes í”ŒëŸ¬ê·¸ì¸ ë°”ë¡œ ì•„ë˜ì— ì¶”ê°€
...
kubernetes:kubernetes
multicluster:github.com/coredns/multicluster
...

# CoreDNS ë¹Œë“œ (arm64)
GOOS=linux GOARCH=arm64 make

# Docker ì´ë¯¸ì§€ ë¹Œë“œ
# ë¦¬ëˆ…ìŠ¤ aarch64(arm64) ì•„í‚¤í…ì²˜ë¡œ ë¹Œë“œí•˜ë ¤ë©´ ì•„ë˜ì™€ ê°™ì´ --platform ì˜µì…˜ì„ ë³€ê²½í•˜ì„¸ìš”.
docker build --platform=linux/arm64 -t coredns:multicluster .

# kind í´ëŸ¬ìŠ¤í„°ì˜ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œì— ì´ë¯¸ì§€ ì§ì ‘ ë¡œë“œ
kind load docker-image coredns:multicluster --name west
kind load docker-image coredns:multicluster --name east
```

##### CoreDNS RBAC ê¶Œí•œ ì¶”ê°€

ServiceImport ë¦¬ì†ŒìŠ¤ë¥¼ ì½ì„ ìˆ˜ ìˆë„ë¡ CoreDNSì— ê¶Œí•œì„ ë¶€ì—¬í•©ë‹ˆë‹¤.

```bash
# West í´ëŸ¬ìŠ¤í„°
kubectl patch clusterrole system:coredns --type=json --context kind-west \
   -p='[{"op":"add","path":"/rules/-","value":{"apiGroups":["multicluster.x-k8s.io"],"resources":["serviceimports"],"verbs":["list","watch"]}}]'

# East í´ëŸ¬ìŠ¤í„°
kubectl patch clusterrole system:coredns --type=json --context kind-east \
   -p='[{"op":"add","path":"/rules/-","value":{"apiGroups":["multicluster.x-k8s.io"],"resources":["serviceimports"],"verbs":["list","watch"]}}]'
```

##### CoreDNS Corefile ìˆ˜ì •

multicluster í”ŒëŸ¬ê·¸ì¸ì„ í™œì„±í™”í•˜ê¸° ìœ„í•´ Corefileì„ ìˆ˜ì •í•©ë‹ˆë‹¤.

```bash
# West í´ëŸ¬ìŠ¤í„°
kubectl edit configmap -n kube-system coredns --context kind-west
kubectl get configmap -n kube-system coredns --context kind-west -oyaml

# East í´ëŸ¬ìŠ¤í„°  
kubectl edit configmap -n kube-system coredns --context kind-east
kubectl get configmap -n kube-system coredns --context kind-east -oyaml

# Corefile: |
#   .:53 {
#       errors
#       health {
#          lameduck 5s
#       }
#       ready
#       multicluster clusterset.local
#       kubernetes cluster.local in-addr.arpa ip6.arpa {
#          pods insecure
#          fallthrough in-addr.arpa ip6.arpa
#          ttl 30
#       }
#       prometheus :9153
#       forward . /etc/resolv.conf {
#          max_concurrent 1000
#       }
#       cache 30 {
#          disable success cluster.local
#          disable denial cluster.local
#       }
#       loop
#       reload
#       loadbalance
#   }

# CoreDNS ì¬ì‹œì‘ ë° ì¬ë°°í¬
kubectl set image deployment/coredns -n kube-system coredns=coredns:multicluster --context kind-west
kubectl set image deployment/coredns -n kube-system coredns=coredns:multicluster --context kind-east

kubectl rollout restart deployment/coredns -n kube-system --context kind-west
kubectl rollout restart deployment/coredns -n kube-system --context kind-east
```

> **ğŸ’¡ ì°¸ê³ :** Ciliumì˜ MCS API êµ¬í˜„ì€ CoreDNS multicluster í”ŒëŸ¬ê·¸ì¸ ì—†ì´ë„ ê¸°ë³¸ì ì¸ ë™ì‘ì€ ê°€ëŠ¥í•˜ì§€ë§Œ, `clusterset.local` ë„ë©”ì¸ì„ í†µí•œ í‘œì¤€ DNS ì¡°íšŒëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” multicluster í”ŒëŸ¬ê·¸ì¸ ì„¤ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

### ì„œë¹„ìŠ¤ ë‚´ë³´ë‚´ê¸° (Exporting a Service)

ì„œë¹„ìŠ¤ë¥¼ ë‚´ë³´ë‚´ë ¤ë©´ ServiceExport ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë©´ í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì— ì„œë¹„ìŠ¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ìˆëŠ” ê²½ìš° ëª¨ë“  í´ëŸ¬ìŠ¤í„°ë¡œ ì„œë¹„ìŠ¤ê°€ ë‚´ë³´ë‚´ì§‘ë‹ˆë‹¤.

```yaml
apiVersion: multicluster.x-k8s.io/v1alpha1
kind: ServiceExport
metadata:
  name: rebel-base
  namespace: default
```

ëª¨ë“  í´ëŸ¬ìŠ¤í„°ì™€ ë™ì¼í•œ ì´ë¦„ê³¼ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ê°€ì§„ ê° ë‚´ë³´ë‚¸ ì„œë¹„ìŠ¤ ì„¸íŠ¸ì— ëŒ€í•´ ServiceImport ë¦¬ì†ŒìŠ¤ê°€ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤. ë™ì¼í•œ ì´ë¦„ê³¼ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ê°€ì§„ í•´ë‹¹ ë‚´ë³´ë‚¸ ì„œë¹„ìŠ¤ì˜ ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ëŠ” ë³‘í•©ë˜ì–´ ì „ì—­ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ë©ë‹ˆë‹¤.

#### DNS ë„ë©”ì¸ êµ¬ì¡°

MCS-APIë¥¼ í†µí•´ ë‚´ë³´ë‚¸ ì„œë¹„ìŠ¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ `<svc>.<ns>.svc.clusterset.local` ë„ë©”ì¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Podì— í˜¸ìŠ¤íŠ¸ ì´ë¦„(ì˜ˆ: StatefulSet)ì„ ì •ì˜í•œ ê²½ìš°, ê° PodëŠ” `<hostname>.<clustername>.<svc>.<ns>.svc.clusterset.local` ë„ë©”ì¸ì„ í†µí•´ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> **âš ï¸ ì£¼ì˜:** íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ì„œë¹„ìŠ¤ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” `<clustername>.<svc>.<ns>.svc.clusterset.local` ë„ë©”ì¸ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤!

ì´ëŸ¬í•œ ë™ì‘ì„ ì›í•˜ì‹ ë‹¤ë©´ í´ëŸ¬ìŠ¤í„° ë°/ë˜ëŠ” ë¦¬ì „ë‹¹ í•˜ë‚˜ì˜ ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ê·¸ì— ë”°ë¼ ë‚´ë³´ë‚´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í•˜ë‚˜ì˜ ì„œë¹„ìŠ¤ë§Œ ìƒì„±í•˜ëŠ” ëŒ€ì‹  `mysvc-eu`ì™€ `mysvc-us` ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë‚´ë³´ë‚´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

### ClusterMesh ì—°ê²° ì„¤ì •

MCS APIê°€ ì‘ë™í•˜ë ¤ë©´ ë¨¼ì € ClusterMeshë¥¼ í™œì„±í™”í•˜ê³  í´ëŸ¬ìŠ¤í„° ê°„ ì—°ê²°ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
# ClusterMesh í™œì„±í™”
cilium clustermesh enable --context kind-west --service-type NodePort
cilium clustermesh enable --context kind-east --service-type NodePort

# ìƒíƒœ í™•ì¸ (Ready ìƒíƒœê¹Œì§€ ëŒ€ê¸°)
cilium clustermesh status --context kind-west --wait
cilium clustermesh status --context kind-east --wait

# í´ëŸ¬ìŠ¤í„° ì—°ê²°
cilium clustermesh connect --context kind-west --destination-context kind-east

# ì—°ê²° ìƒíƒœ í™•ì¸
cilium clustermesh status --context kind-west --wait
cilium clustermesh status --context kind-east --wait

# âš ï¸  Service type NodePort detected! Service may fail when nodes are removed from the cluster!
# âœ… Service "clustermesh-apiserver" of type "NodePort" found
# âœ… Cluster access information is available:
#   - 192.168.97.3:32379
# âœ… Deployment clustermesh-apiserver is ready
# â„¹ï¸  KVStoreMesh is enabled

# âœ… All 2 nodes are connected to all clusters [min:1 / avg:1.0 / max:1]
# âœ… All 1 KVStoreMesh replicas are connected to all clusters [min:1 / avg:1.0 / max:1]

# ğŸ”Œ Cluster Connections:
#   - east: 2/2 configured, 2/2 connected - KVStoreMesh: 1/1 configured, 1/1 connected

# ğŸ”€ Global services: [ min:3 / avg:3.0 / max:3 ]

# âš ï¸  Service type NodePort detected! Service may fail when nodes are removed from the cluster!
# âœ… Service "clustermesh-apiserver" of type "NodePort" found
# âœ… Cluster access information is available:
#   - 192.168.97.5:32379
# âœ… Deployment clustermesh-apiserver is ready
# â„¹ï¸  KVStoreMesh is enabled

# âœ… All 2 nodes are connected to all clusters [min:1 / avg:1.0 / max:1]
# âœ… All 1 KVStoreMesh replicas are connected to all clusters [min:1 / avg:1.0 / max:1]

# ğŸ”Œ Cluster Connections:
#   - west: 2/2 configured, 2/2 connected - KVStoreMesh: 1/1 configured, 1/1 connected

# ğŸ”€ Global services: [ min:3 / avg:3.0 / max:3 ]
```

### MCS-APIë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì˜ˆì œ ì„œë¹„ìŠ¤ ë°°í¬

#### Cluster 1 (West) ë°°í¬

```bash
# Cilium ì˜ˆì œ ì„œë¹„ìŠ¤ ë°°í¬
kubectl apply --context kind-west -f https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/clustermesh/cluster1.yaml

# MCS API ì˜ˆì œ ë°°í¬
kubectl apply --context kind-west -f https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/clustermesh/mcsapi-example.yaml
```

#### Cluster 2 (East) ë°°í¬

```bash
# Cilium ì˜ˆì œ ì„œë¹„ìŠ¤ ë°°í¬
kubectl apply --context kind-east -f https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/clustermesh/cluster2.yaml

# MCS API ì˜ˆì œ ë°°í¬
kubectl apply --context kind-east -f https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/clustermesh/mcsapi-example.yaml
```

#### ë‚´ë³´ë‚¸ ì„œë¹„ìŠ¤ ì•¡ì„¸ìŠ¤

ë‘ í´ëŸ¬ìŠ¤í„° ì¤‘ í•˜ë‚˜ì—ì„œ ë‚´ë³´ë‚¸ ì„œë¹„ìŠ¤ì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤.

```bash
# West í´ëŸ¬ìŠ¤í„°ì—ì„œ í…ŒìŠ¤íŠ¸
kubectl exec -ti deployment/x-wing --context kind-west -- curl rebel-base-mcsapi.default.svc.clusterset.local

# ë˜ëŠ” ì—¬ëŸ¬ ë²ˆ ìš”ì²­í•˜ì—¬ í´ëŸ¬ìŠ¤í„° ë¶„ì‚° í™•ì¸
for i in {1..10}; do
  kubectl exec deployment/x-wing --context kind-west -- curl -s rebel-base-mcsapi.default.svc.clusterset.local
done

# ë‘ í´ëŸ¬ìŠ¤í„°ì˜ Podì—ì„œ ì‘ë‹µì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
# {"Galaxy": "Alderaan", "Cluster": "Cluster-1"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-1"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-1"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-1"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-2"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-1"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-2"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-1"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-2"}
# {"Galaxy": "Alderaan", "Cluster": "Cluster-1"}
```

> **ğŸ’¡ ì°¸ê³ :** clusterset.local ë„ë©”ì¸ì´ ì‘ë™í•˜ë ¤ë©´ CoreDNS multicluster í”ŒëŸ¬ê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. í”ŒëŸ¬ê·¸ì¸ì´ ì—†ëŠ” ê²½ìš°, ServiceImportì˜ ClusterIPë¥¼ ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
> ```bash
> # ServiceImport IP í™•ì¸
> SVC_IP=$(kubectl get serviceimport rebel-base-mcsapi -o jsonpath='{.spec.ips[0]}' --context kind-west)
> kubectl exec deployment/x-wing --context kind-west -- curl $SVC_IP
> ```

### ServiceImport ìƒíƒœ í™•ì¸

```bash
# ServiceImport ìë™ ìƒì„± í™•ì¸
kwest get serviceimport rebel-base-mcsapi -n default
keast get serviceimport rebel-base-mcsapi -n default

# NAME                TYPE           IP                 AGE
# rebel-base-mcsapi   ClusterSetIP   ["10.2.235.195"]   32s
# NAME                TYPE           IP                 AGE
# rebel-base-mcsapi   ClusterSetIP   ["10.3.191.219"]   32s

```

### ClusterMesh vs MCS API ë¹„êµ

#### ClusterMesh ë°©ì‹

**ì¥ì :**
- âœ… Cilium ë„¤ì´í‹°ë¸Œ ê¸°ëŠ¥ìœ¼ë¡œ ì„¤ì •ì´ ê°„ë‹¨
- âœ… `service.cilium.io/global` ì–´ë…¸í…Œì´ì…˜ë§Œìœ¼ë¡œ ê¸€ë¡œë²Œ ì„œë¹„ìŠ¤ í™œì„±í™”
- âœ… Service Affinity(local/remote) ì„¸ë°€í•œ ì œì–´ ê°€ëŠ¥
- âœ… ê¸°ì¡´ DNS ì´ë¦„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
- âœ… ì‹¤ì‹œê°„ ì—”ë“œí¬ì¸íŠ¸ ìƒíƒœ ì¶”ì 
- âœ… Hubbleì„ í†µí•œ ê°€ì‹œì„±

**ë‹¨ì :**
- âŒ Cilium ì „ìš© ê¸°ëŠ¥ìœ¼ë¡œ ë²¤ë” ì¢…ì†ì„±
- âŒ í‘œì¤€ Kubernetes APIê°€ ì•„ë‹˜
- âŒ ë‹¤ë¥¸ CNI/Service Meshì™€ í˜¸í™˜ì„± ì œí•œ

#### MCS API ë°©ì‹

**ì¥ì :**
- âœ… Kubernetes í‘œì¤€ API (KEP-1645)
- âœ… ë²¤ë” ì¤‘ë¦½ì ì¸ ì ‘ê·¼ ë°©ì‹
- âœ… ë‹¤ë¥¸ Service Mesh ì†”ë£¨ì…˜ê³¼ í˜¸í™˜ ê°€ëŠ¥
- âœ… ëª…ì‹œì ì¸ ì„œë¹„ìŠ¤ ë…¸ì¶œ ì œì–´ (ServiceExport)
- âœ… Gateway APIì™€ í†µí•© ê°€ëŠ¥

**ë‹¨ì :**
- âŒ ì¶”ê°€ CRD ì„¤ì¹˜ í•„ìš”
- âŒ CoreDNS ì„¤ì • ë³€ê²½ í•„ìš” (clusterset.local ë„ë©”ì¸)
- âŒ ì•„ì§ ë² íƒ€ ê¸°ëŠ¥ìœ¼ë¡œ ì„±ìˆ™ë„ ë‚®ìŒ
- âŒ Service Affinity ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ ì œí•œ
- âŒ Ciliumì—ì„œëŠ” ì‹¤ì§ˆì ìœ¼ë¡œ ClusterMesh ìœ„ì—ì„œ ë™ì‘

```bash
# ì „ì²´ Kind í´ëŸ¬ìŠ¤í„° ì •ë¦¬
kind delete clusters east
kind delete clusters west
```

---
